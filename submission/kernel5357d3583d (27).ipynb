{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from catboost import Pool, cv, CatBoostClassifier, CatBoostRegressor\n",
    "import catboost as cb\n",
    "import catboost.utils as cbu\n",
    "import hyperopt\n",
    "import sys\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train= pd.read_csv(\"/kaggle/input/widsdatathon2020/training_v2.csv\", header=0)\n",
    "test = pd.read_csv(\"/kaggle/input/widsdatathon2020/unlabeled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "nan_dict = {}\n",
    "for i in range(len(train.index)) :\n",
    "    nan_dict[i] = train.iloc[i].isnull().sum()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "nan_dict_seleted = {}\n",
    "for k, v in sorted(nan_dict.items(), key=lambda item: item[1], reverse = True):\n",
    "    if v > 130:\n",
    "        nan_dict_seleted[k] = v\n",
    "print('--------------' + str(len(nan_dict_seleted))+ '----------------')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "death_0 = 0\n",
    "death_1 = 0\n",
    "nan_dict_seleted_remove = []\n",
    "for i in nan_dict_seleted:\n",
    "    if train.iloc[i].hospital_death == 0: \n",
    "        death_0 = death_0 + 1\n",
    "        nan_dict_seleted_remove.append(i)\n",
    "    if train.iloc[i].hospital_death == 1 : death_1 = death_1 + 1\n",
    "print(death_0)\n",
    "print(death_1)\n",
    "print(death_0/death_1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.drop(nan_dict_seleted_remove,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train['apache_4a_hospital_death_prob'].fillna(train['apache_4a_hospital_death_prob'].median(), inplace=True)\n",
    "#test['apache_4a_hospital_death_prob'].fillna(test['apache_4a_hospital_death_prob'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.utils import class_weight\n",
    "#cw = list(class_weight.compute_class_weight('balanced',np.unique(train['hospital_death']),train['hospital_death']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_categorical_cols = []\n",
    "train_numerical_cols = []\n",
    "for c in  train.columns:\n",
    "    if(train[c].dtype=='object'):\n",
    "        train_categorical_cols.append(c)\n",
    "    else:\n",
    "        train_numerical_cols.append(c)\n",
    "test_categorical_cols = []\n",
    "test_numerical_cols = []\n",
    "for c in  test.columns:\n",
    "    if(test[c].dtype=='object'):\n",
    "        test_categorical_cols.append(c)\n",
    "    else:\n",
    "        test_numerical_cols.append(c)\n",
    "\n",
    "print(train_categorical_cols)\n",
    "print(len(train_categorical_cols))\n",
    "print(len(train_numerical_cols))\n",
    "print(test_categorical_cols)\n",
    "print(len(test_categorical_cols))\n",
    "print(len(test_numerical_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_cat = ['hospital_death','gcs_eyes_apache','gcs_motor_apache','gcs_unable_apache','gcs_verbal_apache']\n",
    "new_cat_cols = []\n",
    "'''\n",
    "for col in train_numerical_cols:\n",
    "    if train[col].nunique() < 3 and col not in ignore_cat:\n",
    "        new_cat_cols.append(col)\n",
    "print(new_cat_cols)\n",
    "print(len(new_cat_cols))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def replace_missing_value(df, number_features):\n",
    "    imputer = SimpleImputer(missing_values=np.nan, strategy=\"mean\")\n",
    "    df_num = df[number_features]\n",
    "    imputer.fit(df_num)\n",
    "    print(df[number_features].head())\n",
    "    df[number_features] = imputer.transform(df_num)\n",
    "    return df\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train[['apache_4a_hospital_death_prob','apache_4a_icu_death_prob']].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "train.loc[train['apache_4a_hospital_death_prob'].isna(), 'apache_4a_hospital_death_prob'] = -1\n",
    "train.loc[train['apache_4a_icu_death_prob'].isna(), 'apache_4a_icu_death_prob'] = -1\n",
    "test.loc[test['apache_4a_hospital_death_prob'].isna(), 'apache_4a_hospital_death_prob'] = -1\n",
    "test.loc[test['apache_4a_icu_death_prob'].isna(), 'apache_4a_icu_death_prob'] = -1\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train[train['apache_4a_hospital_death_prob'] ==-1]['apache_4a_hospital_death_prob'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train[['apache_4a_hospital_death_prob','apache_4a_icu_death_prob']] = train[['apache_4a_hospital_death_prob','apache_4a_icu_death_prob']].fillna(-1)\n",
    "#test[['apache_4a_hospital_death_prob','apache_4a_icu_death_prob']] = test[['apache_4a_hospital_death_prob','apache_4a_icu_death_prob']].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ahd_imp=SimpleImputer(missing_values=-1,strategy=\"median\" )\n",
    "ahd_imp.fit(train[[\"apache_4a_hospital_death_prob\"]])\n",
    "train[\"apache_4a_hospital_death_prob\"]=ahd_imp.transform(train[[\"apache_4a_hospital_death_prob\"]])\n",
    "test[\"apache_4a_hospital_death_prob\"]=ahd_imp.transform(test[[\"apache_4a_hospital_death_prob\"]])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ahd_imp=SimpleImputer(missing_values=-1,strategy=\"median\" )\n",
    "ahd_imp.fit(train[[\"apache_4a_icu_death_prob\"]])\n",
    "train[\"apache_4a_icu_death_prob\"]=ahd_imp.transform(train[[\"apache_4a_icu_death_prob\"]])\n",
    "test[\"apache_4a_icu_death_prob\"]=ahd_imp.transform(test[[\"apache_4a_icu_death_prob\"]])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'apache_4a_hospital_death_prob' in train_numerical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_remove = [\n",
    "    'apache_post_operative','d1_albumin_max','d1_albumin_min','d1_bilirubin_max','d1_bilirubin_min','d1_bun_max','d1_bun_min','d1_creatinine_max',\n",
    "    'd1_creatinine_min','d1_diasbp_noninvasive_max','d1_diasbp_noninvasive_min','d1_glucose_max','d1_hemaglobin_min','d1_hematocrit_max','d1_hematocrit_min',\n",
    "    'd1_mbp_noninvasive_max','d1_mbp_noninvasive_min','d1_platelets_min','d1_sodium_min','d1_sysbp_noninvasive_max','d1_sysbp_noninvasive_min','d1_wbc_max','d1_wbc_min',\n",
    "    'h1_albumin_min','h1_arterial_pco2_max','h1_arterial_pco2_min','h1_arterial_ph_min','h1_bilirubin_max','h1_bilirubin_min','h1_bun_max','h1_bun_min','h1_calcium_min',\n",
    "    'h1_creatinine_max','h1_creatinine_min', 'h1_diasbp_noninvasive_max','h1_diasbp_noninvasive_min','h1_glucose_min', 'h1_hco3_max', 'h1_hco3_min', 'h1_hemaglobin_max',\n",
    "    'h1_hemaglobin_min', 'h1_hematocrit_max', 'h1_hematocrit_min', 'h1_inr_max', 'h1_inr_min','h1_lactate_max','h1_lactate_min','h1_mbp_noninvasive_max','h1_mbp_noninvasive_min',\n",
    "    'h1_pao2fio2ratio_min','h1_platelets_max','h1_platelets_min','h1_potassium_min','h1_sodium_min', 'h1_sysbp_noninvasive_max','h1_sysbp_noninvasive_min','h1_wbc_max','h1_wbc_min',\n",
    "    'paco2_for_ph_apache','readmission_status'\n",
    "    ]\n",
    "\n",
    "'''\n",
    "cols_to_remove = [\n",
    "    'd1_albumin_max', 'd1_bilirubin_max', 'd1_bilirubin_min', 'd1_bun_max','d1_bun_min','d1_creatinine_max',\n",
    "    'd1_creatinine_min','d1_diasbp_noninvasive_max','d1_diasbp_noninvasive_min', 'd1_hematocrit_max', 'd1_mbp_noninvasive_max','d1_mbp_noninvasive_min', 'd1_platelets_min',\n",
    "    'd1_sysbp_noninvasive_max','d1_sysbp_noninvasive_min','d1_wbc_max', 'h1_albumin_min', 'h1_arterial_pco2_min','h1_bilirubin_max','h1_bilirubin_min','h1_bun_min',\n",
    "    'h1_calcium_min',\n",
    "    'h1_creatinine_max','h1_creatinine_min', 'h1_diasbp_noninvasive_max','h1_diasbp_noninvasive_min','h1_glucose_min', 'h1_hco3_min', 'h1_hemaglobin_min', 'h1_hematocrit_min',\n",
    "    'h1_inr_max', 'h1_inr_min', 'h1_lactate_min', 'h1_mbp_noninvasive_max','h1_mbp_noninvasive_min', 'h1_platelets_min', 'h1_sodium_min', \n",
    "    'h1_sysbp_noninvasive_max','h1_sysbp_noninvasive_min', 'h1_wbc_min', 'paco2_for_ph_apache','readmission_status'\n",
    "]\n",
    "'''\n",
    "cols_to_remove = [\n",
    "    'h1_inr_max', 'h1_inr_min', 'paco2_for_ph_apache','readmission_status',\n",
    "    'd1_bilirubin_max','d1_creatinine_max','d1_diasbp_noninvasive_max','d1_diasbp_noninvasive_min','d1_mbp_noninvasive_min',\n",
    "    'd1_sysbp_noninvasive_max','d1_sysbp_noninvasive_min','h1_albumin_min','h1_bilirubin_min','h1_bun_min',\n",
    "    'h1_creatinine_min','h1_hco3_min','h1_mbp_noninvasive_min','h1_platelets_min','h1_sysbp_noninvasive_max','h1_wbc_min'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cols_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.setdiff1d(cols_to_remove, train_numerical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.setdiff1d(cols_to_remove, train_categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(np.setdiff1d(new_cat_cols, cols_to_remove))\n",
    "#print(np.setdiff1d(new_cat_cols, train_categorical_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train[['encounter_id','apache_4a_hospital_death_prob']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['gcs'] = train[['gcs_eyes_apache','gcs_motor_apache','gcs_unable_apache','gcs_verbal_apache']].mean(axis =1)\n",
    "test['gcs'] = test[['gcs_eyes_apache','gcs_motor_apache','gcs_unable_apache','gcs_verbal_apache']].mean(axis =1)\n",
    "#train['gcs'] = train[['gcs_eyes_apache','gcs_motor_apache','gcs_unable_apache','gcs_verbal_apache']].sum(axis =1)\n",
    "#test['gcs'] = test[['gcs_eyes_apache','gcs_motor_apache','gcs_unable_apache','gcs_verbal_apache']].sum(axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.loc[:,[\"gcs\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train[train['gcs_unable_apache']==1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "train[train['age'].isna() & (train['apache_3j_bodysystem']=='Cardiovascular')]['age'] = 67\n",
    "train[train['age'].isna() & (train['apache_3j_bodysystem']=='Gastrointestinal')]['age'] = 72\n",
    "train[train['age'].isna() & (train['apache_3j_bodysystem']=='Cardiovascular')]['age'] = 67\n",
    "train[train['age'].isna() & (train['apache_3j_bodysystem']=='Genitourinary')]['age'] = 70\n",
    "train[train['age'].isna() & (train['apache_3j_bodysystem']=='Gynecological')]['age'] = 34\n",
    "train[train['age'].isna() & (train['apache_3j_bodysystem']=='Hematological')]['age'] = 70\n",
    "train[train['age'].isna() & (train['apache_3j_bodysystem']=='Metabolic')]['age'] = 60\n",
    "train[train['age'].isna() & (train['apache_3j_bodysystem']=='Musculoskeletal/Skin')]['age'] = 64\n",
    "train[train['age'].isna() & (train['apache_3j_bodysystem']=='Neurological')]['age'] = 70\n",
    "train[train['age'].isna() & (train['apache_3j_bodysystem']=='Respiratory')]['age'] = 68\n",
    "train[train['age'].isna() & (train['apache_3j_bodysystem']=='Sepsis')]['age'] = 70\n",
    "train[train['age'].isna() & (train['apache_3j_bodysystem']=='Trauma')]['age'] = 75\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.crosstab(train['hospital_death'], train['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.crosstab(train.hospital_death,train[train['gcs'].isna()]['gcs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['gcs'].fillna(train['gcs'].mean(), inplace = True)\n",
    "test['gcs'].fillna(test['gcs'].mean(), inplace = True)\n",
    "#train['gcs'].value_counts()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = replace_missing_value(train, train_numerical_cols)\n",
    "#train[test_numerical_cols].apply(lambda x: x.fillna(x.mean()),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test[test_numerical_cols].fillna(test[test_numerical_cols].mean(), inplace=True)\n",
    "#test[test_numerical_cols].apply(lambda x: x.fillna(x.mean()),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test[test_numerical_cols].isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(train.loc[train['hospital_admit_source']=='Observation'].index, inplace=True)\n",
    "#train.drop(train.loc[train['gender'].isna()].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for col in train_categorical_cols:\n",
    "    print('\\n' + col)\n",
    "    print(train[col].unique())\n",
    "    print(test[col].unique())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100 - (7907 / 91678) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.loc[train['hospital_death']== 1].count()\n",
    "#91678  - 7907\n",
    "83771 / 7907"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train[train['apache_2_bodysystem'] == 'Undefined Diagnoses'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train['hospital_admit_source'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train[train['apache_2_bodysystem'] == 'Undefined diagnoses'].count()\n",
    "train.loc[train['apache_2_bodysystem'] == 'Undefined Diagnoses', 'apache_2_bodysystem'] = 'Undefined diagnoses'\n",
    "test.loc[test['apache_2_bodysystem'] == 'Undefined Diagnoses', 'apache_2_bodysystem'] = 'Undefined diagnoses'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['apache_2_bodysystem'] = train['apache_2_bodysystem'].fillna(\"Undefined diagnoses\")\n",
    "test['apache_2_bodysystem'] = test['apache_2_bodysystem'].fillna(\"Undefined diagnoses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eth = 'Other/Unknown'\n",
    "#eth = 'Caucasian'\n",
    "train['ethnicity'] = train['ethnicity'].fillna(eth)\n",
    "test['ethnicity'] = test['ethnicity'].fillna(eth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['hospital_admit_source'] = train['hospital_admit_source'].fillna(\"Other\")\n",
    "test['hospital_admit_source'] = test['hospital_admit_source'].fillna(\"Other\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['icu_admit_source'] = train['icu_admit_source'].fillna(\"Other ICU\")\n",
    "test['icu_admit_source'] = test['icu_admit_source'].fillna(\"Other ICU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['gender'] = train['gender'].fillna(\"NA\")\n",
    "test['gender'] = test['gender'].fillna(\"NA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train_categorical_cols] = train[train_categorical_cols].fillna(\"NA\")\n",
    "test[test_categorical_cols] = test[test_categorical_cols].fillna(\"NA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train[train_numerical_cols] = train[train_numerical_cols].fillna(train[train_numerical_cols].median())\n",
    "#test[test_numerical_cols] = test[test_numerical_cols].fillna(test[test_numerical_cols].median())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train[train_numerical_cols].isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_allcols = train.columns.values.tolist()\n",
    "test_allcols = test.columns.values.tolist()\n",
    "allcols = train.columns.values.tolist()\n",
    "inputcols = allcols[4:]\n",
    "outputcols = allcols[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputcols.remove('gcs_eyes_apache')\n",
    "inputcols.remove('gcs_motor_apache')\n",
    "inputcols.remove('gcs_unable_apache')\n",
    "inputcols.remove('gcs_verbal_apache')\n",
    "#inputcols.remove('icu_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(inputcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "cols_to_remove.append('h1_inr_max')\n",
    "cols_to_remove.append('h1_inr_min')\n",
    "cols_to_remove.append('paco2_for_ph_apache')\n",
    "cols_to_remove.append('d1_bilirubin_max')\n",
    "cols_to_remove.append('d1_bilirubin_min')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for col in cols_to_remove:\n",
    "    inputcols.remove(col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(inputcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in new_cat_cols:\n",
    "    if col in inputcols:\n",
    "        print('---------------'+ col+ '---------------')\n",
    "        if(train[col].isna().sum()==0):\n",
    "            train_categorical_cols.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_categorical_cols.remove('ethnicity')\n",
    "#test_categorical_cols.remove('ethnicity')\n",
    "#inputcols.remove('ethnicity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'ethnicity' in inputcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[inputcols]\n",
    "y = train[outputcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pool = Pool(data=X,label = y,cat_features=train_categorical_cols,\n",
    "#                   baseline= X_train[\"\"], ## \n",
    "                   #group_id = ['encounter_id']\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xtrain,xtest,ytrain,ytest = train_test_split(X,y,train_size=.8,random_state=1234)\n",
    "#model = CatBoostClassifier(learning_rate=0.08166369766256530,l2_leaf_reg = 8.836837790286535, loss_function='Logloss',custom_metric= ['AUC'],eval_metric='Accuracy',use_best_model=True,random_seed=42)\n",
    "#model.fit(xtrain,ytrain,cat_features=train_categorical_cols,eval_set=(xtest,ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('Tree count: ' + str(model.tree_count_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf.get_best_score()['learn']['Logloss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 83773/7903 # 83773/7903"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for i in nan_dict_seleted:\n",
    "    print(train.iloc[i].hospital_death)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.iloc[3011]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions = []\n",
    "scale_pos_weight = 10.594536486657391\n",
    "\n",
    "#0.07260908767\n",
    "lcount = 0\n",
    "for i in range(60):\n",
    "    print('-------------' + str(i) + '----------------------')\n",
    "    clf = CatBoostClassifier(learning_rate=0.08166369766256530, depth = 10,loss_function='Logloss', eval_metric = 'AUC', \n",
    "                             custom_metric= ['AUC'], iterations=1000, l2_leaf_reg = 8.836837790286535,task_type=\"CPU\", random_seed=i, logging_level='Silent')\n",
    "    clf.fit(train_pool, plot=False,silent=True)\n",
    "    #print('Tree count: ' + str(clf.tree_count_))\n",
    "    #print(clf.get_best_score())\n",
    "    #if clf.get_best_score()['learn']['Logloss'] < 0.0599:\n",
    "    #    lcount = lcount + 1\n",
    "    predictions.append(clf.predict_proba(test[inputcols])[:,1])\n",
    "print(lcount)    \n",
    "prediction = np.mean(predictions, axis=0)\n",
    "test[\"hospital_death\"] = prediction\n",
    "test[[\"encounter_id\",\"hospital_death\"]].to_csv(\"1910.csv\",index=False)\n",
    "#{'learn': {'Logloss': 0.08512141544067534}} # 08177070126274019 #08000100126274019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "predictions = []\n",
    "scale_pos_weight = 10.594536486657391\n",
    "\n",
    "#0.07260908767\n",
    "lcount = 0\n",
    "for i in range(10):\n",
    "    clf = CatBoostClassifier(learning_rate=0.08166369766256530005, depth = 10,loss_function='Logloss', eval_metric = 'AUC', \n",
    "                             custom_metric= ['AUC'], iterations=1000, l2_leaf_reg = 8.836837790286535,task_type=\"GPU\", random_seed=i, logging_level='Silent')\n",
    "    clf.fit(train_pool, plot=True,silent=True)\n",
    "    print(clf.get_best_score())\n",
    "    if clf.get_best_score()['learn']['Logloss'] < 0.0595:\n",
    "        lcount = lcount + 1\n",
    "    predictions.append(clf.predict_proba(test[inputcols])[:,1])\n",
    "print(lcount)    \n",
    "prediction = np.mean(predictions, axis=0)\n",
    "test[\"hospital_death\"] = prediction\n",
    "test[[\"encounter_id\",\"hospital_death\"]].to_csv(\"1906.csv\",index=False)\n",
    "#{'learn': {'Logloss': 0.08512141544067534}} # 08177070126274019 #08000100126274019\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "params = {}\n",
    "params['loss_function'] = 'Logloss'\n",
    "params['iterations'] = 551\n",
    "params['custom_loss'] = 'AUC'\n",
    "params['random_seed'] = 63\n",
    "params['learning_rate'] = 0.5\n",
    "\n",
    "cv_data = cv(\n",
    "    params = params,\n",
    "    pool = Pool(X, label=y, cat_features=train_categorical_cols),\n",
    "    fold_count = 5,\n",
    "    type = 'Classical',\n",
    "    shuffle=True,\n",
    "    partition_random_seed=0,\n",
    "    plot=True,\n",
    "    stratified=True,\n",
    "    verbose=False\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "best_value = np.min(cv_data['test-Logloss-mean'])\n",
    "best_iter = np.argmin(cv_data['test-Logloss-mean'])\n",
    "\n",
    "print('Best validation Logloss score, stratified: {:.4f} ± {:.4f} on step {}'.format(\n",
    "    best_value,\n",
    "    cv_data['test-Logloss-std'][best_iter],\n",
    "    best_iter)\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "predictions = []\n",
    "scale_pos_weight = 10.594536486657391\n",
    "\n",
    "\n",
    "\n",
    "#0.07260908767\n",
    "for i in range(1):\n",
    "    clf = CatBoostClassifier(learning_rate=0.062338418743052904, depth = 5,loss_function='Logloss', eval_metric = 'Accuracy', \n",
    "                             custom_metric= ['AUC'], iterations=1000, l2_leaf_reg = 6.706159252357066,task_type=\"GPU\", random_seed=20181224, logging_level='Silent')\n",
    "    clf.fit(train_pool, plot=True,silent=True, use_best_model = True)\n",
    "    predictions.append(clf.predict_proba(test[inputcols])[:,1])\n",
    "    print(clf.get_best_score())\n",
    "    \n",
    "prediction = np.mean(predictions, axis=0)\n",
    "test[\"hospital_death\"] = prediction\n",
    "test[[\"encounter_id\",\"hospital_death\"]].to_csv(\"1801.csv\",index=False)\n",
    "#{'learn': {'Logloss': 0.08512141544067534}} # 08177070126274019 #08000100126274019\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "predictions = []\n",
    "scale_pos_weight = 10.594536486657391\n",
    "\n",
    "#0.07260908767\n",
    "for i in range(10):\n",
    "    clf = CatBoostClassifier(learning_rate=0.08166369766256530, depth = 10,loss_function='Logloss', eval_metric = 'AUC', \n",
    "                             custom_metric= ['AUC'], iterations=1000, l2_leaf_reg = 8.836837790286535,task_type=\"GPU\", random_seed=i, logging_level='Silent')\n",
    "    clf.fit(train_pool, plot=True,silent=True)\n",
    "    predictions.append(clf.predict_proba(test[inputcols])[:,1])\n",
    "    print(clf.get_best_score())\n",
    "    \n",
    "prediction = np.mean(predictions, axis=0)\n",
    "test[\"hospital_death\"] = prediction\n",
    "test[[\"encounter_id\",\"hospital_death\"]].to_csv(\"1504.csv\",index=False)\n",
    "#{'learn': {'Logloss': 0.08512141544067534}} # 08177070126274019 #08000100126274019\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "predictions = []\n",
    "scale_pos_weight = 10.594536486657391\n",
    "\n",
    "#0.07260908767\n",
    "for i in range(10):\n",
    "    clf = CatBoostClassifier(learning_rate=0.08166369766256534, depth = 10,loss_function='Logloss', eval_metric = 'AUC', \n",
    "                             custom_metric= ['AUC'], iterations=1000, l2_leaf_reg = 8.835837790286535,task_type=\"GPU\", random_seed=i, logging_level='Silent')\n",
    "    clf.fit(train_pool, plot=True,silent=True)\n",
    "    predictions.append(clf.predict_proba(test[inputcols])[:,1])\n",
    "    print(clf.get_best_score())\n",
    "    \n",
    "prediction = np.mean(predictions, axis=0)\n",
    "test[\"hospital_death\"] = prediction\n",
    "test[[\"encounter_id\",\"hospital_death\"]].to_csv(\"1102.csv\",index=False)\n",
    "#{'learn': {'Logloss': 0.08512141544067534}} # 08177070126274019 #08000100126274019\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "predictions = []\n",
    "scale_pos_weight = 10.594536486657391\n",
    "\n",
    "#0.07260908767\n",
    "for i in range(10):\n",
    "    clf = CatBoostClassifier(learning_rate=0.08166369766256534, depth = 10,loss_function='Logloss', eval_metric = 'AUC', \n",
    "                             custom_metric= ['AUC'], iterations=1000, l2_leaf_reg = 8.836837790286535,task_type=\"GPU\", random_seed=i, logging_level='Silent')\n",
    "    clf.fit(train_pool, plot=True,silent=True)\n",
    "    predictions.append(clf.predict_proba(test[inputcols])[:,1])\n",
    "    print(clf.get_best_score())\n",
    "    \n",
    "prediction = np.mean(predictions, axis=0)\n",
    "test[\"hospital_death\"] = prediction\n",
    "test[[\"encounter_id\",\"hospital_death\"]].to_csv(\"1103.csv\",index=False)\n",
    "#{'learn': {'Logloss': 0.08512141544067534}} # 08177070126274019 #08000100126274019\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "predictions = []\n",
    "scale_pos_weight = 10.594536486657391\n",
    "\n",
    "#0.07260908767\n",
    "for i in range(10):\n",
    "    clf = CatBoostClassifier(learning_rate=0.08166369766256530, depth = 10,loss_function='Logloss', eval_metric = 'AUC', \n",
    "                             custom_metric= ['AUC'], iterations=1000, l2_leaf_reg = 8.835837790286535,task_type=\"GPU\", random_seed=i, logging_level='Silent')\n",
    "    clf.fit(train_pool, plot=True,silent=True)\n",
    "    predictions.append(clf.predict_proba(test[inputcols])[:,1])\n",
    "    print(clf.get_best_score())\n",
    "    \n",
    "prediction = np.mean(predictions, axis=0)\n",
    "test[\"hospital_death\"] = prediction\n",
    "test[[\"encounter_id\",\"hospital_death\"]].to_csv(\"1104.csv\",index=False)\n",
    "#{'learn': {'Logloss': 0.08512141544067534}} # 08177070126274019 #08000100126274019\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "### hyperparameter tuning example grid for catboost : \n",
    "'''\n",
    "grid = {'learning_rate': [0.01, 0.04],\n",
    "        'depth': [10],\n",
    "        #'l2_leaf_reg': [3,4,5],\n",
    "        \"iterations\": [500],\n",
    "        \"custom_metric\":['Logloss', 'AUC']}\n",
    "\n",
    "model = CatBoostClassifier(task_type=\"GPU\")\n",
    "\n",
    "## can also do randomized search - more efficient typically, especially for large search space - `randomized_search`\n",
    "grid_search_result = model.grid_search(grid, \n",
    "                                       train_pool,\n",
    "                                       plot=True,\n",
    "                                       refit = True, #  refit best model on all data\n",
    "                                      partition_random_seed=42)\n",
    "\n",
    "print(model.get_best_score())\n",
    "print(\"best model params: \\n\",grid_search_result[\"params\"])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "predictions = []\n",
    "scale_pos_weight = 10.594536486657391\n",
    "\n",
    "#0.07260908767\n",
    "for i in range(10):\n",
    "    clf = CatBoostClassifier(learning_rate=0.08000100126274019, depth = 10,loss_function='Logloss', eval_metric = 'AUC', \n",
    "                             custom_metric= ['AUC'], iterations=1000, l2_leaf_reg = 4,task_type=\"GPU\", random_seed=i, logging_level='Silent')\n",
    "    clf.fit(train_pool, plot=True,silent=True)\n",
    "    predictions.append(clf.predict_proba(test[inputcols])[:,1])\n",
    "    print(clf.get_best_score())\n",
    "    \n",
    "prediction = np.mean(predictions, axis=0)\n",
    "test[\"hospital_death\"] = prediction\n",
    "test[[\"encounter_id\",\"hospital_death\"]].to_csv(\"0901.csv\",index=False)\n",
    "#{'learn': {'Logloss': 0.08512141544067534}} # 08177070126274019 #08000100126274019\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "predictions = []\n",
    "scale_pos_weight = 10.594536486657391\n",
    "\n",
    "#0.07260908767\n",
    "for i in range(10):\n",
    "    clf = CatBoostClassifier(learning_rate=0.08000100126274019, boosting_type='Ordered', depth = 10,loss_function='Logloss', eval_metric = 'AUC', custom_metric= ['AUC'], iterations=1000, l2_leaf_reg = 4,task_type=\"GPU\", random_seed=i, logging_level='Silent')\n",
    "    clf.fit(train_pool, plot=True,silent=True)\n",
    "    predictions.append(clf.predict_proba(test[inputcols])[:,1])\n",
    "    print(clf.get_best_score())\n",
    "    \n",
    "prediction = np.mean(predictions, axis=0)\n",
    "test[\"hospital_death\"] = prediction\n",
    "test[[\"encounter_id\",\"hospital_death\"]].to_csv(\"0902.csv\",index=False)\n",
    "#{'learn': {'Logloss': 0.08512141544067534}} # 08177070126274019 #08000100126274019\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "predictions = []\n",
    "scale_pos_weight = 10.594536486657391\n",
    "\n",
    "#0.07260908767\n",
    "for i in range(10):\n",
    "    clf = CatBoostClassifier(learning_rate=0.08277070126274019,depth = 10,loss_function='Logloss', eval_metric = 'AUC', custom_metric= ['AUC'], iterations=1000, l2_leaf_reg = 4,task_type=\"GPU\", random_seed=i, logging_level='Silent')\n",
    "    clf.fit(train_pool, plot=True,silent=True)\n",
    "    predictions.append(clf.predict_proba(test[inputcols])[:,1])\n",
    "    print(clf.get_best_score())\n",
    "    \n",
    "prediction = np.mean(predictions, axis=0)\n",
    "test[\"hospital_death\"] = prediction\n",
    "test[[\"encounter_id\",\"hospital_death\"]].to_csv(\"0217.csv\",index=False)\n",
    "#{'learn': {'Logloss': 0.08512141544067534}}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "class UciAdultClassifierObjective(object):\n",
    "    def __init__(self, dataset, const_params, fold_count):\n",
    "        self._dataset = dataset\n",
    "        self._const_params = const_params.copy()\n",
    "        self._fold_count = fold_count\n",
    "        self._evaluated_count = 0\n",
    "        \n",
    "    def _to_catboost_params(self, hyper_params):\n",
    "        return {\n",
    "            'learning_rate': hyper_params['learning_rate'],\n",
    "            'depth': hyper_params['depth'],\n",
    "            'l2_leaf_reg': hyper_params['l2_leaf_reg']}\n",
    "    \n",
    "    # hyperopt optimizes an objective using `__call__` method (e.g. by doing \n",
    "    # `foo(hyper_params)`), so we provide one\n",
    "    def __call__(self, hyper_params):\n",
    "        # join hyper-parameters provided by hyperopt with hyper-parameters \n",
    "        # provided by the user\n",
    "        params = self._to_catboost_params(hyper_params)\n",
    "        params.update(self._const_params)\n",
    "        \n",
    "        print('evaluating params={}'.format(params), file=sys.stdout)\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        # we use cross-validation for objective evaluation, to avoid overfitting\n",
    "        scores = cb.cv(\n",
    "            pool=self._dataset,\n",
    "            params=params,\n",
    "            fold_count=self._fold_count,\n",
    "            partition_random_seed=20181224,\n",
    "            verbose=False)\n",
    "        \n",
    "        # scores returns a dictionary with mean and std (per-fold) of metric \n",
    "        # value for each cv iteration, we choose minimal value of objective \n",
    "        # mean (though it will be better to choose minimal value among all folds)\n",
    "        # because noise is additive\n",
    "        max_mean_auc = np.max(scores['test-AUC-mean'])\n",
    "        print('evaluated score={}'.format(max_mean_auc), file=sys.stdout)\n",
    "        \n",
    "        self._evaluated_count += 1\n",
    "        print('evaluated {} times'.format(self._evaluated_count), file=sys.stdout)\n",
    "        \n",
    "        # negate because hyperopt minimizes the objective\n",
    "        return {'loss': -max_mean_auc, 'status': hyperopt.STATUS_OK}\n",
    "    \n",
    "def find_best_hyper_params(dataset, const_params, max_evals=100):    \n",
    "    # we are going to optimize these three parameters, though there are a lot more of them (see CatBoost docs)\n",
    "    parameter_space = {\n",
    "        'learning_rate': hyperopt.hp.uniform('learning_rate', 0.01, 0.1),\n",
    "        'depth': hyperopt.hp.randint('depth', 12),\n",
    "        'l2_leaf_reg': hyperopt.hp.uniform('l2_leaf_reg', 1, 10)}\n",
    "    objective = UciAdultClassifierObjective(dataset=dataset, const_params=const_params, fold_count=6)\n",
    "    trials = hyperopt.Trials()\n",
    "    best = hyperopt.fmin(\n",
    "        fn=objective,\n",
    "        space=parameter_space,\n",
    "        algo=hyperopt.rand.suggest,\n",
    "        max_evals=max_evals,\n",
    "        rstate=np.random.RandomState(seed=20181224))\n",
    "    return best\n",
    "\n",
    "def train_best_model(X, y, const_params, max_evals=100, use_default=False):\n",
    "    # convert pandas.DataFrame to catboost.Pool to avoid converting it on each \n",
    "    # iteration of hyper-parameters optimization\n",
    "    dataset = Pool(X, y, cat_features=train_categorical_cols)\n",
    "    \n",
    "    if use_default:\n",
    "        # pretrained optimal parameters\n",
    "        best = {\n",
    "            'learning_rate': 0.4234185321620083, \n",
    "            'depth': 5, \n",
    "            'l2_leaf_reg': 9.464266235679002}\n",
    "    else:\n",
    "        best = find_best_hyper_params(dataset, const_params, max_evals=max_evals)\n",
    "    \n",
    "    # merge subset of hyper-parameters provided by hyperopt with hyper-parameters \n",
    "    # provided by the user\n",
    "    hyper_params = best.copy()\n",
    "    hyper_params.update(const_params)\n",
    "    \n",
    "    # drop `use_best_model` because we are going to use entire dataset for \n",
    "    # training of the final model\n",
    "    hyper_params.pop('use_best_model', None)\n",
    "    \n",
    "    model = cb.CatBoostClassifier(**hyper_params)\n",
    "    model.fit(dataset, verbose=False)\n",
    "    \n",
    "    return model, hyper_params\n",
    "\n",
    "\n",
    "# make it True if your want to use GPU for training\n",
    "have_gpu = False\n",
    "# skip hyper-parameter optimization and just use provided optimal parameters\n",
    "use_optimal_pretrained_params = False\n",
    "# number of iterations of hyper-parameter search\n",
    "hyperopt_iterations = 15\n",
    "\n",
    "const_params = dict({\n",
    "    'task_type': 'GPU' if have_gpu else 'CPU',\n",
    "    'loss_function': 'Logloss',\n",
    "    'eval_metric': 'AUC', \n",
    "    'custom_metric': ['AUC'],\n",
    "    'iterations': 1000,\n",
    "    'random_seed': 20181224})\n",
    "\n",
    "model, params = train_best_model(\n",
    "    X, y, \n",
    "    const_params, \n",
    "    max_evals=hyperopt_iterations, \n",
    "    use_default=use_optimal_pretrained_params)\n",
    "print('best params are {}'.format(params), file=sys.stdout)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('hyper completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "predictions = []\n",
    "scale_pos_weight = 10.594536486657391\n",
    "random_seed = 20181224\n",
    "\n",
    "#0.07260908767\n",
    "for i in range(10):\n",
    "    clf = CatBoostClassifier(learning_rate=0.08577070126274019,depth = 10,loss_function='Logloss', \n",
    "                             eval_metric = 'AUC', custom_metric= ['AUC'], iterations=1000, \n",
    "                             l2_leaf_reg = 4,task_type=\"GPU\", random_seed=i, logging_level='Silent')\n",
    "    clf.fit(train_pool, plot=True,silent=True)\n",
    "    predictions.append(clf.predict_proba(test[inputcols])[:,1])\n",
    "    print(clf.get_best_score())\n",
    "    \n",
    "prediction = np.mean(predictions, axis=0)\n",
    "test[\"hospital_death\"] = prediction\n",
    "test[[\"encounter_id\",\"hospital_death\"]].to_csv(\"0212.csv\",index=False)\n",
    "#{'learn': {'Logloss': 0.08512141544067534}}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "predictions = []\n",
    "scale_pos_weight = 10.594536486657391\n",
    "random_seed = 20181224\n",
    "\n",
    "#0.07260908767\n",
    "for i in range(10):\n",
    "    clf = CatBoostClassifier(learning_rate=0.08277070126274019,depth = 10,loss_function='Logloss', \n",
    "                             eval_metric = 'AUC', custom_metric= ['AUC'], iterations=1000, \n",
    "                             l2_leaf_reg = 4,task_type=\"GPU\", random_seed=i, logging_level='Silent')\n",
    "    clf.fit(train_pool, plot=True,silent=True)\n",
    "    predictions.append(clf.predict_proba(test[inputcols])[:,1])\n",
    "    print(clf.get_best_score())\n",
    "    \n",
    "prediction = np.mean(predictions, axis=0)\n",
    "test[\"hospital_death\"] = prediction\n",
    "test[[\"encounter_id\",\"hospital_death\"]].to_csv(\"0210.csv\",index=False)\n",
    "#{'learn': {'Logloss': 0.08512141544067534}}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
